{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3eb15b",
   "metadata": {},
   "source": [
    "# Market Risk Early Warning System - Sentiment Analysis\n",
    "\n",
    "This notebook demonstrates the sentiment analysis component of MEWS, including:\n",
    "- News data collection from GNews API\n",
    "- VADER sentiment analysis\n",
    "- Sentiment aggregation and scoring\n",
    "- Integration with risk predictions\n",
    "- Real-time sentiment monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Sentiment analysis libraries\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK data is downloaded\n",
    "try:\n",
    "    nltk.data.find('vader_lexicon')\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon')\n",
    "\n",
    "# Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"VADER sentiment analyzer ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b6c53",
   "metadata": {},
   "source": [
    "## GNews API Integration\n",
    "\n",
    "First, let's set up the GNews API integration for fetching financial news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffcd90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsCollector:\n",
    "    \"\"\"Collect and analyze financial news sentiment\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=None):\n",
    "        self.api_key = api_key or \"0903e69179300b9e3117cdc721c14366\"  # Default API key\n",
    "        self.base_url = \"https://gnews.io/api/v4/search\"\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "        \n",
    "    def fetch_gnews_sentiment(self, symbols, days=7, max_articles=50):\n",
    "        \"\"\"Fetch news sentiment from GNews API\"\"\"\n",
    "        \n",
    "        if not self.api_key:\n",
    "            print(\"❌ No API key provided\")\n",
    "            return None\n",
    "        \n",
    "        all_news = []\n",
    "        \n",
    "        print(f\"🔍 Fetching news for {len(symbols)} symbols over {days} days...\")\n",
    "        \n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                # Calculate date range\n",
    "                end_date = datetime.now()\n",
    "                start_date = end_date - timedelta(days=days)\n",
    "                \n",
    "                # API parameters\n",
    "                params = {\n",
    "                    'q': f'{symbol} stock market financial',\n",
    "                    'token': self.api_key,\n",
    "                    'lang': 'en',\n",
    "                    'country': 'us',\n",
    "                    'max': min(max_articles, 10),  # GNews API limits\n",
    "                    'from': start_date.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "                    'to': end_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "                }\n",
    "                \n",
    "                # Make API request\n",
    "                response = requests.get(self.base_url, params=params, timeout=10)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    articles = data.get('articles', [])\n",
    "                    \n",
    "                    print(f\"  ✅ {symbol}: {len(articles)} articles found\")\n",
    "                    \n",
    "                    for article in articles:\n",
    "                        news_item = {\n",
    "                            'symbol': symbol,\n",
    "                            'title': article.get('title', ''),\n",
    "                            'description': article.get('description', ''),\n",
    "                            'content': article.get('content', ''),\n",
    "                            'published_date': article.get('publishedAt', ''),\n",
    "                            'source': article.get('source', {}).get('name', ''),\n",
    "                            'url': article.get('url', '')\n",
    "                        }\n",
    "                        all_news.append(news_item)\n",
    "                else:\n",
    "                    print(f\"  ❌ {symbol}: API request failed ({response.status_code})\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ {symbol}: Error - {str(e)}\")\n",
    "        \n",
    "        print(f\"📰 Total articles collected: {len(all_news)}\")\n",
    "        return pd.DataFrame(all_news) if all_news else None\n",
    "    \n",
    "    def analyze_sentiment(self, text):\n",
    "        \"\"\"Analyze sentiment of text using VADER\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return {'compound': 0.0, 'pos': 0.0, 'neu': 0.0, 'neg': 0.0}\n",
    "        \n",
    "        scores = self.analyzer.polarity_scores(str(text))\n",
    "        return scores\n",
    "    \n",
    "    def process_news_sentiment(self, news_df):\n",
    "        \"\"\"Process news dataframe and add sentiment scores\"\"\"\n",
    "        if news_df is None or news_df.empty:\n",
    "            return None\n",
    "        \n",
    "        print(\"🔄 Analyzing sentiment for all articles...\")\n",
    "        \n",
    "        # Combine title and description for sentiment analysis\n",
    "        news_df['combined_text'] = (\n",
    "            news_df['title'].fillna('') + ' ' + \n",
    "            news_df['description'].fillna('')\n",
    "        )\n",
    "        \n",
    "        # Analyze sentiment for each article\n",
    "        sentiment_scores = []\n",
    "        for text in news_df['combined_text']:\n",
    "            scores = self.analyze_sentiment(text)\n",
    "            sentiment_scores.append(scores)\n",
    "        \n",
    "        # Convert to DataFrame and merge\n",
    "        sentiment_df = pd.DataFrame(sentiment_scores)\n",
    "        result_df = pd.concat([news_df, sentiment_df], axis=1)\n",
    "        \n",
    "        # Add sentiment interpretation\n",
    "        result_df['sentiment_label'] = result_df['compound'].apply(\n",
    "            lambda x: 'Positive' if x > 0.05 else ('Negative' if x < -0.05 else 'Neutral')\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Sentiment analysis completed for {len(result_df)} articles\")\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "# Initialize news collector\n",
    "news_collector = NewsCollector()\n",
    "print(\"📰 News Collector initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d21e53",
   "metadata": {},
   "source": [
    "## Fetch and Analyze Recent News\n",
    "\n",
    "Let's fetch recent news for major stocks and analyze their sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stocks to analyze\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'NVDA', 'JPM', 'BAC']\n",
    "\n",
    "# Fetch news data\n",
    "print(\"🔍 Starting news collection...\")\n",
    "news_df = news_collector.fetch_gnews_sentiment(symbols, days=7, max_articles=50)\n",
    "\n",
    "if news_df is not None and not news_df.empty:\n",
    "    print(f\"📊 News data shape: {news_df.shape}\")\n",
    "    print(f\"📈 Symbols covered: {news_df['symbol'].unique()}\")\n",
    "    print(f\"📅 Date range: {news_df['published_date'].min()} to {news_df['published_date'].max()}\")\n",
    "    \n",
    "    # Display sample articles\n",
    "    print(\"\\n📰 Sample Articles:\")\n",
    "    print(\"-\" * 80)\n",
    "    for idx, row in news_df.head(3).iterrows():\n",
    "        print(f\"Symbol: {row['symbol']}\")\n",
    "        print(f\"Title: {row['title']}\")\n",
    "        print(f\"Source: {row['source']}\")\n",
    "        print(f\"Date: {row['published_date']}\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"❌ No news data available. Using sample data for demonstration.\")\n",
    "    \n",
    "    # Create sample news data for demonstration\n",
    "    sample_news = [\n",
    "        {\n",
    "            'symbol': 'AAPL',\n",
    "            'title': 'Apple reports strong quarterly earnings with iPhone sales growth',\n",
    "            'description': 'Apple Inc. exceeded expectations with robust iPhone sales and services revenue growth',\n",
    "            'published_date': '2025-09-29T10:30:00Z',\n",
    "            'source': 'Financial News'\n",
    "        },\n",
    "        {\n",
    "            'symbol': 'TSLA',\n",
    "            'title': 'Tesla faces production challenges amid supply chain issues',\n",
    "            'description': 'Electric vehicle manufacturer Tesla encounters manufacturing bottlenecks',\n",
    "            'published_date': '2025-09-29T08:15:00Z',\n",
    "            'source': 'Market Watch'\n",
    "        },\n",
    "        {\n",
    "            'symbol': 'MSFT',\n",
    "            'title': 'Microsoft Azure cloud services show continued expansion',\n",
    "            'description': 'Microsoft Corporation reports significant growth in cloud computing revenue',\n",
    "            'published_date': '2025-09-29T14:20:00Z',\n",
    "            'source': 'Tech Daily'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    news_df = pd.DataFrame(sample_news)\n",
    "    print(f\"📊 Using sample data: {news_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26322cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sentiment analysis\n",
    "if news_df is not None:\n",
    "    sentiment_df = news_collector.process_news_sentiment(news_df)\n",
    "    \n",
    "    if sentiment_df is not None:\n",
    "        print(\"📊 Sentiment Analysis Results:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Display sentiment statistics\n",
    "        print(f\"Total articles analyzed: {len(sentiment_df)}\")\n",
    "        print(f\"Sentiment distribution:\")\n",
    "        print(sentiment_df['sentiment_label'].value_counts())\n",
    "        print(f\"\\nAverage sentiment scores:\")\n",
    "        print(f\"  Compound: {sentiment_df['compound'].mean():.3f}\")\n",
    "        print(f\"  Positive: {sentiment_df['pos'].mean():.3f}\")\n",
    "        print(f\"  Negative: {sentiment_df['neg'].mean():.3f}\")\n",
    "        print(f\"  Neutral: {sentiment_df['neu'].mean():.3f}\")\n",
    "        \n",
    "        # Show sample results\n",
    "        print(f\"\\n📰 Sample Sentiment Results:\")\n",
    "        print(\"-\" * 80)\n",
    "        for idx, row in sentiment_df.head(3).iterrows():\n",
    "            print(f\"Symbol: {row['symbol']}\")\n",
    "            print(f\"Title: {row['title'][:60]}...\")\n",
    "            print(f\"Sentiment: {row['sentiment_label']} (Score: {row['compound']:.3f})\")\n",
    "            print(f\"Positive: {row['pos']:.3f}, Negative: {row['neg']:.3f}, Neutral: {row['neu']:.3f}\")\n",
    "            print(\"-\" * 80)\n",
    "    else:\n",
    "        print(\"❌ Sentiment analysis failed\")\n",
    "else:\n",
    "    print(\"❌ No news data to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841dfbb",
   "metadata": {},
   "source": [
    "## Sentiment Visualization and Analysis\n",
    "\n",
    "Let's create comprehensive visualizations of the sentiment analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ec1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sentiment_df' in locals() and sentiment_df is not None:\n",
    "    \n",
    "    # Create comprehensive sentiment visualizations\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Sentiment Distribution by Stock',\n",
    "            'Sentiment Score Distribution',\n",
    "            'Average Sentiment by Symbol',\n",
    "            'Sentiment Timeline'\n",
    "        ),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"histogram\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Sentiment distribution by stock\n",
    "    sentiment_by_stock = sentiment_df.groupby(['symbol', 'sentiment_label']).size().reset_index(name='count')\n",
    "    \n",
    "    for sentiment in ['Positive', 'Negative', 'Neutral']:\n",
    "        data = sentiment_by_stock[sentiment_by_stock['sentiment_label'] == sentiment]\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name=sentiment,\n",
    "                x=data['symbol'],\n",
    "                y=data['count'],\n",
    "                text=data['count'],\n",
    "                textposition='auto'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. Sentiment score distribution\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=sentiment_df['compound'],\n",
    "            nbinsx=20,\n",
    "            name='Compound Score',\n",
    "            marker_color='lightblue',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Average sentiment by symbol\n",
    "    avg_sentiment = sentiment_df.groupby('symbol')['compound'].mean().reset_index()\n",
    "    avg_sentiment = avg_sentiment.sort_values('compound', ascending=True)\n",
    "    \n",
    "    colors = ['red' if x < -0.05 else 'green' if x > 0.05 else 'gray' for x in avg_sentiment['compound']]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=avg_sentiment['compound'],\n",
    "            y=avg_sentiment['symbol'],\n",
    "            orientation='h',\n",
    "            marker_color=colors,\n",
    "            text=[f'{x:.3f}' for x in avg_sentiment['compound']],\n",
    "            textposition='auto',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Sentiment timeline (if we have dates)\n",
    "    if 'published_date' in sentiment_df.columns:\n",
    "        # Convert dates and create timeline\n",
    "        sentiment_df['date'] = pd.to_datetime(sentiment_df['published_date'])\n",
    "        daily_sentiment = sentiment_df.groupby([sentiment_df['date'].dt.date, 'symbol'])['compound'].mean().reset_index()\n",
    "        \n",
    "        for symbol in sentiment_df['symbol'].unique():\n",
    "            symbol_data = daily_sentiment[daily_sentiment['symbol'] == symbol]\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=symbol_data['date'],\n",
    "                    y=symbol_data['compound'],\n",
    "                    mode='lines+markers',\n",
    "                    name=symbol,\n",
    "                    showlegend=True\n",
    "                ),\n",
    "                row=2, col=2\n",
    "            )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"Financial News Sentiment Analysis Dashboard\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text=\"Symbols\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Article Count\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Compound Sentiment Score\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Average Sentiment Score\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Symbols\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Sentiment Score\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    print(\"📊 Sentiment visualizations created!\")\n",
    "else:\n",
    "    print(\"❌ No sentiment data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3548a",
   "metadata": {},
   "source": [
    "## Sentiment Aggregation and Scoring\n",
    "\n",
    "Let's create aggregated sentiment scores that can be used in the risk prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258af177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_sentiment_scores(sentiment_df, method='weighted_average'):\n",
    "    \"\"\"Aggregate sentiment scores for risk prediction integration\"\"\"\n",
    "    \n",
    "    if sentiment_df is None or sentiment_df.empty:\n",
    "        return None\n",
    "    \n",
    "    print(f\"🔄 Aggregating sentiment scores using {method} method...\")\n",
    "    \n",
    "    # Group by symbol and calculate various aggregations\n",
    "    aggregations = {\n",
    "        'compound': ['mean', 'std', 'min', 'max', 'count'],\n",
    "        'pos': ['mean', 'sum'],\n",
    "        'neg': ['mean', 'sum'],\n",
    "        'neu': ['mean']\n",
    "    }\n",
    "    \n",
    "    sentiment_agg = sentiment_df.groupby('symbol').agg(aggregations).round(4)\n",
    "    sentiment_agg.columns = ['_'.join(col).strip() for col in sentiment_agg.columns]\n",
    "    sentiment_agg = sentiment_agg.reset_index()\n",
    "    \n",
    "    # Calculate weighted sentiment score (considering article count and recency)\n",
    "    sentiment_agg['weighted_sentiment'] = (\n",
    "        sentiment_agg['compound_mean'] * \n",
    "        np.log1p(sentiment_agg['compound_count']) * 0.1  # Weight by article count\n",
    "    )\n",
    "    \n",
    "    # Create sentiment risk indicators\n",
    "    sentiment_agg['sentiment_risk'] = sentiment_agg['compound_mean'].apply(\n",
    "        lambda x: 1 if x < -0.1 else (0.5 if -0.1 <= x < 0.1 else 0)\n",
    "    )\n",
    "    \n",
    "    # Calculate sentiment volatility (how much sentiment varies)\n",
    "    sentiment_agg['sentiment_volatility'] = sentiment_agg['compound_std'].fillna(0)\n",
    "    \n",
    "    # Create composite sentiment score\n",
    "    sentiment_agg['composite_sentiment'] = (\n",
    "        0.6 * sentiment_agg['compound_mean'] +\n",
    "        0.2 * sentiment_agg['pos_mean'] -\n",
    "        0.2 * sentiment_agg['neg_mean']\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Sentiment aggregation completed for {len(sentiment_agg)} symbols\")\n",
    "    \n",
    "    return sentiment_agg\n",
    "\n",
    "def interpret_sentiment_for_users(sentiment_score):\n",
    "    \"\"\"Create user-friendly interpretation of sentiment scores\"\"\"\n",
    "    \n",
    "    interpretations = []\n",
    "    \n",
    "    if sentiment_score > 0.3:\n",
    "        interpretations.append(\"📈 **Strongly Positive**: News sentiment is very bullish, indicating optimism about the stock's prospects.\")\n",
    "    elif sentiment_score > 0.1:\n",
    "        interpretations.append(\"📊 **Moderately Positive**: News sentiment leans positive, suggesting favorable market conditions.\")\n",
    "    elif sentiment_score > -0.1:\n",
    "        interpretations.append(\"😐 **Neutral**: News sentiment is balanced, with mixed positive and negative coverage.\")\n",
    "    elif sentiment_score > -0.3:\n",
    "        interpretations.append(\"📉 **Moderately Negative**: News sentiment leans negative, indicating some concerns or challenges.\")\n",
    "    else:\n",
    "        interpretations.append(\"🚨 **Strongly Negative**: News sentiment is very bearish, suggesting significant negative developments.\")\n",
    "    \n",
    "    # Add risk implications\n",
    "    if sentiment_score < -0.2:\n",
    "        interpretations.append(\"⚠️ **Risk Implication**: Negative sentiment may indicate increased market risk and potential price volatility.\")\n",
    "    elif sentiment_score > 0.2:\n",
    "        interpretations.append(\"✅ **Risk Implication**: Positive sentiment suggests lower immediate risk and potential upward momentum.\")\n",
    "    else:\n",
    "        interpretations.append(\"🔄 **Risk Implication**: Neutral sentiment indicates stable conditions with no immediate sentiment-driven risk.\")\n",
    "    \n",
    "    return \" \".join(interpretations)\n",
    "\n",
    "# Aggregate sentiment scores\n",
    "if 'sentiment_df' in locals() and sentiment_df is not None:\n",
    "    sentiment_aggregated = aggregate_sentiment_scores(sentiment_df)\n",
    "    \n",
    "    if sentiment_aggregated is not None:\n",
    "        print(\"📊 AGGREGATED SENTIMENT RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Display results\n",
    "        for idx, row in sentiment_aggregated.iterrows():\n",
    "            symbol = row['symbol']\n",
    "            avg_sentiment = row['compound_mean']\n",
    "            risk_score = row['sentiment_risk']\n",
    "            \n",
    "            print(f\"\\n{symbol}:\")\n",
    "            print(f\"  Average Sentiment: {avg_sentiment:.3f}\")\n",
    "            print(f\"  Risk Score: {risk_score:.1f}\")\n",
    "            print(f\"  Article Count: {int(row['compound_count'])}\")\n",
    "            print(f\"  Interpretation: {interpret_sentiment_for_users(avg_sentiment)}\")\n",
    "        \n",
    "        # Save aggregated results\n",
    "        output_file = \"../data/sentiment_aggregated.csv\"\n",
    "        sentiment_aggregated.to_csv(output_file, index=False)\n",
    "        print(f\"\\n💾 Sentiment data saved to: {output_file}\")\n",
    "    else:\n",
    "        print(\"❌ Sentiment aggregation failed\")\n",
    "else:\n",
    "    print(\"❌ No sentiment data to aggregate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281bead6",
   "metadata": {},
   "source": [
    "## Real-time Sentiment Monitoring Function\n",
    "\n",
    "Let's create a function that can be used for real-time sentiment monitoring in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_sentiment_realtime(symbols, api_key, lookback_hours=24):\n",
    "    \"\"\"Real-time sentiment monitoring function for production use\"\"\"\n",
    "    \n",
    "    print(f\"🔍 Starting real-time sentiment monitoring for {len(symbols)} symbols...\")\n",
    "    print(f\"Lookback period: {lookback_hours} hours\")\n",
    "    \n",
    "    collector = NewsCollector(api_key)\n",
    "    \n",
    "    # Fetch recent news\n",
    "    lookback_days = max(1, lookback_hours // 24)\n",
    "    news_df = collector.fetch_gnews_sentiment(symbols, days=lookback_days)\n",
    "    \n",
    "    if news_df is None or news_df.empty:\n",
    "        print(\"⚠️ No recent news found\")\n",
    "        return None\n",
    "    \n",
    "    # Filter to recent hours if needed\n",
    "    if lookback_hours < 24:\n",
    "        cutoff_time = datetime.now() - timedelta(hours=lookback_hours)\n",
    "        news_df['published_date'] = pd.to_datetime(news_df['published_date'])\n",
    "        news_df = news_df[news_df['published_date'] >= cutoff_time]\n",
    "    \n",
    "    # Analyze sentiment\n",
    "    sentiment_df = collector.process_news_sentiment(news_df)\n",
    "    \n",
    "    if sentiment_df is None:\n",
    "        print(\"❌ Sentiment analysis failed\")\n",
    "        return None\n",
    "    \n",
    "    # Create summary report\n",
    "    summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'symbols_analyzed': symbols,\n",
    "        'total_articles': len(sentiment_df),\n",
    "        'sentiment_summary': {}\n",
    "    }\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        symbol_data = sentiment_df[sentiment_df['symbol'] == symbol]\n",
    "        \n",
    "        if not symbol_data.empty:\n",
    "            avg_sentiment = symbol_data['compound'].mean()\n",
    "            article_count = len(symbol_data)\n",
    "            \n",
    "            summary['sentiment_summary'][symbol] = {\n",
    "                'average_sentiment': round(avg_sentiment, 3),\n",
    "                'article_count': article_count,\n",
    "                'sentiment_label': 'Positive' if avg_sentiment > 0.05 else ('Negative' if avg_sentiment < -0.05 else 'Neutral'),\n",
    "                'risk_indicator': 'High' if avg_sentiment < -0.2 else ('Low' if avg_sentiment > 0.2 else 'Medium'),\n",
    "                'interpretation': interpret_sentiment_for_users(avg_sentiment)\n",
    "            }\n",
    "        else:\n",
    "            summary['sentiment_summary'][symbol] = {\n",
    "                'average_sentiment': 0.0,\n",
    "                'article_count': 0,\n",
    "                'sentiment_label': 'No Data',\n",
    "                'risk_indicator': 'Unknown',\n",
    "                'interpretation': 'No recent news available for sentiment analysis.'\n",
    "            }\n",
    "    \n",
    "    print(\"✅ Real-time sentiment monitoring completed!\")\n",
    "    return summary\n",
    "\n",
    "# Example of real-time monitoring\n",
    "if 'news_collector' in locals():\n",
    "    print(\"\\n🔄 Testing real-time sentiment monitoring...\")\n",
    "    \n",
    "    test_symbols = ['AAPL', 'TSLA', 'MSFT']\n",
    "    monitoring_result = monitor_sentiment_realtime(\n",
    "        symbols=test_symbols,\n",
    "        api_key=\"0903e69179300b9e3117cdc721c14366\",\n",
    "        lookback_hours=24\n",
    "    )\n",
    "    \n",
    "    if monitoring_result:\n",
    "        print(\"\\n📊 REAL-TIME SENTIMENT MONITORING RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Timestamp: {monitoring_result['timestamp']}\")\n",
    "        print(f\"Total Articles: {monitoring_result['total_articles']}\")\n",
    "        \n",
    "        for symbol, data in monitoring_result['sentiment_summary'].items():\n",
    "            print(f\"\\n{symbol}:\")\n",
    "            print(f\"  Sentiment: {data['sentiment_label']} ({data['average_sentiment']})\")\n",
    "            print(f\"  Risk Level: {data['risk_indicator']}\")\n",
    "            print(f\"  Articles: {data['article_count']}\")\n",
    "            print(f\"  Analysis: {data['interpretation'][:100]}...\")\n",
    "    else:\n",
    "        print(\"❌ Real-time monitoring test failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610e996",
   "metadata": {},
   "source": [
    "## Integration with Risk Prediction Models\n",
    "\n",
    "Let's show how sentiment data integrates with the ML risk prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d812135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_features_for_ml(sentiment_aggregated):\n",
    "    \"\"\"Create sentiment features that can be used in ML risk models\"\"\"\n",
    "    \n",
    "    if sentiment_aggregated is None:\n",
    "        return None\n",
    "    \n",
    "    print(\"🔄 Creating sentiment features for ML integration...\")\n",
    "    \n",
    "    # Create feature set for ML models\n",
    "    ml_features = sentiment_aggregated[['symbol']].copy()\n",
    "    \n",
    "    # Direct sentiment features\n",
    "    ml_features['sentiment_compound'] = sentiment_aggregated['compound_mean']\n",
    "    ml_features['sentiment_volatility'] = sentiment_aggregated['sentiment_volatility']\n",
    "    ml_features['sentiment_positive'] = sentiment_aggregated['pos_mean']\n",
    "    ml_features['sentiment_negative'] = sentiment_aggregated['neg_mean']\n",
    "    \n",
    "    # Derived features\n",
    "    ml_features['sentiment_strength'] = abs(sentiment_aggregated['compound_mean'])\n",
    "    ml_features['sentiment_bias'] = (\n",
    "        sentiment_aggregated['pos_mean'] - sentiment_aggregated['neg_mean']\n",
    "    )\n",
    "    ml_features['news_coverage'] = np.log1p(sentiment_aggregated['compound_count'])\n",
    "    \n",
    "    # Risk indicators\n",
    "    ml_features['sentiment_risk_binary'] = (sentiment_aggregated['compound_mean'] < -0.1).astype(int)\n",
    "    ml_features['sentiment_opportunity'] = (sentiment_aggregated['compound_mean'] > 0.2).astype(int)\n",
    "    \n",
    "    # Sentiment momentum (simplified - would need time series data for real momentum)\n",
    "    ml_features['sentiment_momentum'] = sentiment_aggregated['compound_mean'] * sentiment_aggregated['compound_count']\n",
    "    \n",
    "    print(f\"✅ Created {len(ml_features.columns)-1} sentiment features for ML integration\")\n",
    "    \n",
    "    return ml_features\n",
    "\n",
    "def combine_sentiment_with_market_data(sentiment_features, market_data):\n",
    "    \"\"\"Combine sentiment features with market data for comprehensive risk analysis\"\"\"\n",
    "    \n",
    "    if sentiment_features is None or market_data is None:\n",
    "        print(\"❌ Cannot combine data - missing sentiment or market data\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🔄 Combining sentiment and market data...\")\n",
    "    \n",
    "    # Merge on symbol\n",
    "    combined = market_data.merge(sentiment_features, on='symbol', how='left')\n",
    "    \n",
    "    # Fill missing sentiment data with neutral values\n",
    "    sentiment_cols = [col for col in sentiment_features.columns if col != 'symbol']\n",
    "    combined[sentiment_cols] = combined[sentiment_cols].fillna(0)\n",
    "    \n",
    "    # Create interaction features\n",
    "    if 'Close' in combined.columns:\n",
    "        combined['sentiment_price_interaction'] = combined['sentiment_compound'] * combined['Close']\n",
    "    \n",
    "    if 'Volume' in combined.columns:\n",
    "        combined['sentiment_volume_interaction'] = combined['sentiment_compound'] * combined['Volume']\n",
    "    \n",
    "    print(f\"✅ Combined dataset created: {combined.shape}\")\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Create sentiment features for ML\n",
    "if 'sentiment_aggregated' in locals() and sentiment_aggregated is not None:\n",
    "    \n",
    "    sentiment_features = create_sentiment_features_for_ml(sentiment_aggregated)\n",
    "    \n",
    "    if sentiment_features is not None:\n",
    "        print(\"\\n📊 SENTIMENT FEATURES FOR ML:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Features created: {list(sentiment_features.columns)}\")\n",
    "        print(f\"Sample data:\")\n",
    "        print(sentiment_features.head())\n",
    "        \n",
    "        # Save sentiment features\n",
    "        features_file = \"../data/sentiment_features_ml.csv\"\n",
    "        sentiment_features.to_csv(features_file, index=False)\n",
    "        print(f\"\\n💾 Sentiment features saved to: {features_file}\")\n",
    "        \n",
    "        # Example of how this would integrate with market data\n",
    "        print(\"\\n🔗 INTEGRATION EXAMPLE:\")\n",
    "        print(\"This sentiment data can be merged with market data using:\")\n",
    "        print(\"combined_data = market_df.merge(sentiment_features, on='symbol', how='left')\")\n",
    "        print(\"Then use in ML models as additional features for risk prediction!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No sentiment data available for ML feature creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c387c",
   "metadata": {},
   "source": [
    "## Summary and Production Usage\n",
    "\n",
    "This notebook demonstrated the complete sentiment analysis pipeline for MEWS:\n",
    "\n",
    "### 🎯 **What we accomplished:**\n",
    "- ✅ GNews API integration for financial news collection\n",
    "- ✅ VADER sentiment analysis implementation\n",
    "- ✅ Comprehensive sentiment visualization and analysis\n",
    "- ✅ Sentiment aggregation and scoring for risk assessment\n",
    "- ✅ Real-time sentiment monitoring capabilities\n",
    "- ✅ ML feature engineering from sentiment data\n",
    "- ✅ Integration framework with risk prediction models\n",
    "\n",
    "### 📊 **Key Features:**\n",
    "- **Real-time News**: Fetch up-to-date financial news from multiple sources\n",
    "- **Advanced Sentiment**: VADER analysis with custom interpretations\n",
    "- **Risk Integration**: Sentiment-based risk indicators\n",
    "- **User-Friendly**: Plain English explanations of sentiment analysis\n",
    "- **Production Ready**: Scalable functions for live deployment\n",
    "\n",
    "### 🚀 **Production Usage:**\n",
    "The functions in this notebook are used in:\n",
    "1. **Streamlit Dashboard**: Real-time sentiment display\n",
    "2. **ML Risk Models**: Sentiment as additional features\n",
    "3. **Risk Timeline**: Sentiment-driven risk assessment\n",
    "4. **Automated Monitoring**: Scheduled sentiment updates\n",
    "\n",
    "### 📈 **Business Value:**\n",
    "- **Early Warning**: Detect sentiment shifts before price movements\n",
    "- **Risk Management**: Quantify news-driven market risk\n",
    "- **Decision Support**: Data-driven insights for investment decisions\n",
    "- **Market Intelligence**: Comprehensive view of market sentiment\n",
    "\n",
    "The sentiment analysis system is now ready for production deployment! 🎉"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
